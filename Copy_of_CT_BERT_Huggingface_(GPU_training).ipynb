{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CT-BERT - Huggingface (GPU training)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44eaa1bf3cbb4c99a08802eb711e1a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cab93932d4ab4fc2a4276bdb49f3030f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36e0b1978c914e3e9592e252908e7861",
              "IPY_MODEL_d55b9c22ab4b4b3592ff68ff26ae8605"
            ]
          }
        },
        "cab93932d4ab4fc2a4276bdb49f3030f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36e0b1978c914e3e9592e252908e7861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1debb53f45a3438baab6756059516bad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_448c39b445214d53ad07eb2ead253898"
          }
        },
        "d55b9c22ab4b4b3592ff68ff26ae8605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e37c5da39d444cd91fa62bc759688a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:11&lt;00:00, 38.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbb9ae123970499da827670d7398f5cc"
          }
        },
        "1debb53f45a3438baab6756059516bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "448c39b445214d53ad07eb2ead253898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e37c5da39d444cd91fa62bc759688a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbb9ae123970499da827670d7398f5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdaf1af3e61f498c85dc2ecf8f43ed98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fa98da8e0c64793a77a6c41d5d88f70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca5c6f62748e4aa98847d7430d593f35",
              "IPY_MODEL_29227c89b7eb4f6697a5edaef41b219d"
            ]
          }
        },
        "3fa98da8e0c64793a77a6c41d5d88f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca5c6f62748e4aa98847d7430d593f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e0e2329cbb1444b9d70a141f7ca67d0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf6feea6f6214e11819a09cf54f6d88b"
          }
        },
        "29227c89b7eb4f6697a5edaef41b219d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_406b42c04b96425ca8b9a2d0067186c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e0e46ae229f4719aa8aa896be5ef082"
          }
        },
        "1e0e2329cbb1444b9d70a141f7ca67d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf6feea6f6214e11819a09cf54f6d88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "406b42c04b96425ca8b9a2d0067186c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e0e46ae229f4719aa8aa896be5ef082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8de7e36f78d74cfaa31422fa520f637e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c628df35b97e4e3b8cbd747eb2174b9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10868752dd1249269194bd9916e81bec",
              "IPY_MODEL_efab9a9034134c869d66ba01ddc5b781"
            ]
          }
        },
        "c628df35b97e4e3b8cbd747eb2174b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10868752dd1249269194bd9916e81bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5356ddc3732e4880b57310d80a070b60",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1472566816,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1472566816,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b09ce2eae4d49bdbebb8c12cd9a2518"
          }
        },
        "efab9a9034134c869d66ba01ddc5b781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c8ec813b23146f7b1544d740f8db977",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.47G/1.47G [00:32&lt;00:00, 44.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7be5879c156f4ba3893edc66b9344606"
          }
        },
        "5356ddc3732e4880b57310d80a070b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b09ce2eae4d49bdbebb8c12cd9a2518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c8ec813b23146f7b1544d740f8db977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7be5879c156f4ba3893edc66b9344606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ok111886/2nd-ML100Days/blob/master/Copy_of_CT_BERT_Huggingface_(GPU_training).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3gcwjDTd4oY"
      },
      "source": [
        "<img align=\"right\" width=\"450px\" src=\"https://github.com/digitalepidemiologylab/covid-twitter-bert/raw/master/images/COVID-Twitter-BERT-medium.png\">\n",
        "\n",
        "# Finetuning COVID-Twitter-BERT using Huggingface\n",
        "In this notebook we will finetune CT-BERT for sentiment classification using the transformer library by Huggingface.\n",
        "\n",
        "Learn more about this library [here](https://huggingface.co/transformers/).\n",
        "\n",
        "## Before proceeding\n",
        "Create a copy of this notebook by going to \"File - Save a Copy in Drive\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVsmxmSberX2"
      },
      "source": [
        "# Install transformers and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_k-GwPM9JXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b049b9-c1e0-45e6-9cbe-2297d50dc3de"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 33.2MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvvPnOFQH2pR"
      },
      "source": [
        "from transformers import (\n",
        "   AutoConfig,\n",
        "   AutoTokenizer,\n",
        "   TFAutoModelForSequenceClassification,\n",
        "   AdamW,\n",
        "   glue_convert_examples_to_features\n",
        ")\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrDpLTI7Jt5p"
      },
      "source": [
        "# Choose a Model from the Huggingface Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyLIi4bvImJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "44eaa1bf3cbb4c99a08802eb711e1a07",
            "cab93932d4ab4fc2a4276bdb49f3030f",
            "36e0b1978c914e3e9592e252908e7861",
            "d55b9c22ab4b4b3592ff68ff26ae8605",
            "1debb53f45a3438baab6756059516bad",
            "448c39b445214d53ad07eb2ead253898",
            "2e37c5da39d444cd91fa62bc759688a3",
            "bbb9ae123970499da827670d7398f5cc",
            "cdaf1af3e61f498c85dc2ecf8f43ed98",
            "3fa98da8e0c64793a77a6c41d5d88f70",
            "ca5c6f62748e4aa98847d7430d593f35",
            "29227c89b7eb4f6697a5edaef41b219d",
            "1e0e2329cbb1444b9d70a141f7ca67d0",
            "bf6feea6f6214e11819a09cf54f6d88b",
            "406b42c04b96425ca8b9a2d0067186c3",
            "7e0e46ae229f4719aa8aa896be5ef082"
          ]
        },
        "outputId": "470293ea-55df-4957-9edc-4fe3cfef1576"
      },
      "source": [
        "# Choose model\n",
        "# @markdown >The default model is <i><b>COVID-Twitter-BERT</b></i>. You can however choose <i><b>BERT Base</i></b> or <i><b>BERT Large</i></b> to compare these models to the <i><b>COVID-Twitter-BERT</i></b>. All these three models will be initiated with a random classification layer. If you go directly to the Predict-cell after having compiled the model, you will see that it still runs the predition. However the output will be random. The training steps below will finetune this for the specific task. <br /><br /> \n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert' #@param [\"digitalepidemiologylab/covid-twitter-bert\", \"bert-large-uncased\", \"bert-base-uncased\"]\n",
        "\n",
        "# Initialise tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44eaa1bf3cbb4c99a08802eb711e1a07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=421.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdaf1af3e61f498c85dc2ecf8f43ed98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqI6yqwnyukj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdiZDL69JpNC"
      },
      "source": [
        "# Download the SST-2 Dataset and Prepare for Finetuning\n",
        "You can skip this step if you are using the already finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11kI0lhIJoxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b12c7d3-1d71-4a9d-a652-b58a76282624"
      },
      "source": [
        "# Paramteters\n",
        "#@markdown >Batch size and sequence length needs to be set to prepare the data. The size of the batches depends on available memory. For Colab GPU limit batch size to 8 and sequence length to 96. By reducing the length of the input (max_seq_length) you can also increase the batch size. For a dataset like SST-2 with lots of short sentences. this will likely benefit training.\n",
        "max_seq_length = 96 #@param {type: \"integer\"}\n",
        "train_batch_size =  8#@param {type: \"integer\"} \n",
        "eval_batch_size = 8 #@param {type: \"integer\"}\n",
        "#需要設置批次大小和序列長度來準備數據。批量的大小取決於可用的內存。對於Colab GPU來說，批次大小限制為8，序列長度為96。通過減少輸入的長度（max_seq_length），你也可以增加批次大小。對於像SST-2這樣有很多短句子的數據集，這可能會有利於訓練。\n",
        "\n",
        "#@markdown >The Glue dataset has around 62000 examples, and we really do not need them all for training a decent model. To cut down training time, please reduse this to only a percentage of the entire set.\n",
        "use_percentage_of_data = 8 #@param {type: \"slider\", min: 1, max: 100}\n",
        "\n",
        "# get dataset sizes\n",
        "#glue_builder = tfds.builder('glue/sst2')\n",
        "glue_builder = tfds.builder('glue/mrpc')#但SST-2因為存取權限問題無法使用，只好改成mrpc數據集\n",
        "num_train_examples = glue_builder.info.splits['train'].num_examples\n",
        "num_dev_examples = glue_builder.info.splits['validation'].num_examples\n",
        "num_labels = glue_builder.info.features['label'].num_classes\n",
        "\n",
        "# 下載數據集並轉換為訓練特徵\n",
        "glue_builder.download_and_prepare()\n",
        "\n",
        "train_data = glue_builder.as_dataset(split='train')\n",
        "train_dataset = glue_convert_examples_to_features(train_data, tokenizer, max_length=max_seq_length,task ='mrpc')\n",
        "train_dataset = train_dataset.shuffle(100).batch(train_batch_size)#打亂順序、並以批次size\n",
        "dev_data = glue_builder.as_dataset(split='validation')\n",
        "dev_dataset = glue_convert_examples_to_features(dev_data, tokenizer, max_length=max_seq_length, task='mrpc')\n",
        "dev_dataset = dev_dataset.shuffle(100).batch(eval_batch_size)\n",
        "\n",
        "# Map the labels for printing\n",
        "label_mapping = {i: glue_builder.info.features['label'].int2str(i) for i in range(num_labels)}\n",
        "\n",
        "print(f'\\n\\nThe dataset is downloaded. The entire dataset has {num_train_examples + num_dev_examples} examples of which you are using {use_percentage_of_data}%. This will result in a train dataset with {int(num_train_examples * (use_percentage_of_data/100))} examples and a validation dataset with {int(num_dev_examples * (use_percentage_of_data/100))} examples.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/glue/mrpc/1.0.0\n",
            "INFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/mrpc/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from /root/tensorflow_datasets/glue/mrpc/1.0.0\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
            "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:175: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
            "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
            "INFO:absl:Constructing tf.data.Dataset for split validation, from /root/tensorflow_datasets/glue/mrpc/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The dataset is downloaded. The entire dataset has 4076 examples of which you are using 8%. This will result in a train dataset with 293 examples and a validation dataset with 32 examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2AsubSgKGDu"
      },
      "source": [
        "# Compile the Model, Train it on the SST-2 Task and Save the Result\n",
        "You can skip this step if you are using the already finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XSbsZFDQTEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8de7e36f78d74cfaa31422fa520f637e",
            "c628df35b97e4e3b8cbd747eb2174b9b",
            "10868752dd1249269194bd9916e81bec",
            "efab9a9034134c869d66ba01ddc5b781",
            "5356ddc3732e4880b57310d80a070b60",
            "4b09ce2eae4d49bdbebb8c12cd9a2518",
            "8c8ec813b23146f7b1544d740f8db977",
            "7be5879c156f4ba3893edc66b9344606"
          ]
        },
        "outputId": "d1c9b978-6947-44a1-d741-e4903389efac"
      },
      "source": [
        "#@markdown >The default learning rate of 2e5 will be fine in most cases\n",
        "learning_rate = 2e-5 #@param {type: \"number\"}#默認\n",
        "\n",
        "#@markdown > Typically these type of models are finetuned for 3 epochs. This can be increased for small datasets and decreased for large datasets.\n",
        "num_epochs =   3#@param {type: \"integer\"}\n",
        "#對於小數據集，這可以增加，對於大數據集可以減少。\n",
        "\n",
        "#初始化一個有2個標籤的序列分類模型\n",
        "config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)#稀疏分類交叉熵\n",
        "\n",
        "# Metrics and callbacks\n",
        "#計算預測匹配整數標籤的頻率。\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
        "checkpoint_path = './checkpoints/checkpoint.{epoch:02d}'\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True)]\n",
        "\n",
        "# Compute some variables\n",
        "train_steps_per_epoch = int(num_train_examples * (use_percentage_of_data/100) / train_batch_size)\n",
        "dev_steps_per_epoch = int(num_dev_examples * (use_percentage_of_data/100) / eval_batch_size)\n",
        "#選擇使用百分之幾的數據集\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, \n",
        "  epochs=num_epochs,\n",
        "  steps_per_epoch=train_steps_per_epoch,\n",
        "  validation_data=dev_dataset,\n",
        "  validation_steps=dev_steps_per_epoch,\n",
        "  callbacks=callbacks)\n",
        "\n",
        "# Print some information about the training\n",
        "print(f'\\nThe training has finished training after {num_epochs} epochs.')\n",
        "print('\\nThe history contains the accuracy and loss at every epoch:')\n",
        "print(json.dumps(history.history, indent=4))\n",
        "\n",
        "print('\\nThe checkpoint callback has generated a checkpoint after every epoch (loss being the training loss, val_loss is the validation loss):')\n",
        "!ls -lha ./checkpoints/\n",
        "\n",
        "print('\\nWe will now save the finetuned model and the corresponding config file on your Colab disk.')\n",
        "model.save_pretrained('./huggingface_model/')\n",
        "\n",
        "print('\\nTensorflow model and config-file is saved in ./huggingface_model/')\n",
        "!ls -lha ./huggingface_model/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8de7e36f78d74cfaa31422fa520f637e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1472566816.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f800bad2e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f800bad2e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f800bad2e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f8027381dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f8027381dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f8027381dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "36/36 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.6389WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/36 [==============================] - 99s 742ms/step - loss: 0.6441 - accuracy: 0.6389 - val_loss: 0.5755 - val_accuracy: 0.7188\n",
            "\n",
            "The training has finished training after 1 epochs.\n",
            "\n",
            "The history contains the accuracy and loss at every epoch:\n",
            "{\n",
            "    \"loss\": [\n",
            "        0.6441203355789185\n",
            "    ],\n",
            "    \"accuracy\": [\n",
            "        0.6388888955116272\n",
            "    ],\n",
            "    \"val_loss\": [\n",
            "        0.5754684209823608\n",
            "    ],\n",
            "    \"val_accuracy\": [\n",
            "        0.71875\n",
            "    ]\n",
            "}\n",
            "\n",
            "The checkpoint callback has generated a checkpoint after every epoch (loss being the training loss, val_loss is the validation loss):\n",
            "total 3.8G\n",
            "drwxr-xr-x 2 root root 4.0K Jun  7 09:22 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun  7 09:20 ..\n",
            "-rw-r--r-- 1 root root   83 Jun  7 09:22 checkpoint\n",
            "-rw-r--r-- 1 root root 3.8G Jun  7 09:22 checkpoint.01.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root  85K Jun  7 09:22 checkpoint.01.index\n",
            "\n",
            "We will now save the finetuned model and the corresponding config file on your Colab disk.\n",
            "\n",
            "Tensorflow model and config-file is saved in ./huggingface_model/\n",
            "total 1.3G\n",
            "drwxr-xr-x 2 root root 4.0K Jun  7 09:22 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun  7 09:22 ..\n",
            "-rw-r--r-- 1 root root  644 Jun  7 09:22 config.json\n",
            "-rw-r--r-- 1 root root 1.3G Jun  7 09:22 tf_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYamwzWeM9vM"
      },
      "source": [
        "# Predict\n",
        "Let's run some inference with the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0zy0fK9Rmx"
      },
      "source": [
        "# Small function only used for formatting the output\n",
        "def format_prediction(preds, label_mapping, label_name):\n",
        "    preds = tf.nn.softmax(preds, axis=1)\n",
        "    formatted_preds = []\n",
        "    for pred in preds.numpy():\n",
        "        # convert to Python types and sort\n",
        "        pred = {label: float(probability) for label, probability in zip(label_mapping.values(), pred)}\n",
        "        pred = {k: v for k, v in sorted(pred.items(), key=lambda item: item[1], reverse=True)}\n",
        "        formatted_preds.append({label_name: list(pred.keys())[0], f'{label_name}_probabilities': pred})\n",
        "    return formatted_preds"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdk8zasnKJWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648a810b-3cd8-4e80-b2f6-9965cb58f0fd"
      },
      "source": [
        "#@markdown >Please input text that the model can try to classify\n",
        "input_text = 'Happy little clouds'  #@param {type: \"string\"}\n",
        "\n",
        "# Tokenize the input \n",
        "input_ids = tf.constant(tokenizer.encode(input_text, add_special_tokens=True))[None, :]\n",
        "\n",
        "# Run predictions\n",
        "preds = model(input_ids)\n",
        "\n",
        "# format logits\n",
        "formatted_preds = format_prediction(preds[0], label_mapping, 'sentiment')\n",
        "\n",
        "print(f'\\nLabel Mapping:{json.dumps(label_mapping, indent=4)}')\n",
        "print(f'\\nLogits: {preds}')\n",
        "print(f'\\nProbabilities:{json.dumps(formatted_preds, indent=4)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Label Mapping:{\n",
            "    \"0\": \"not_equivalent\",\n",
            "    \"1\": \"equivalent\"\n",
            "}\n",
            "\n",
            "Logits: TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.37711567, 0.4411992 ]], dtype=float32)>, hidden_states=None, attentions=None)\n",
            "\n",
            "Probabilities:[\n",
            "    {\n",
            "        \"sentiment\": \"equivalent\",\n",
            "        \"sentiment_probabilities\": {\n",
            "            \"equivalent\": 0.5160154104232788,\n",
            "            \"not_equivalent\": 0.4839845895767212\n",
            "        }\n",
            "    }\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBq1C2U9ScWg"
      },
      "source": [
        "##### Copyright 2020 Per Egil Kummervold and Martin Müller"
      ]
    }
  ]
}